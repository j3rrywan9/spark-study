# Spark: The Definitive Guide

## Chapter 1

Apache Spark is a unified computing engine and a set of libraries for parallel data processing on computer clusters.

## Chapter 2

### Spark's Basic Architecture

A cluster, or group, of computers, pools the resources of many machines together, giving us the ability to use all the cumulative resources as if they were a single computer.
Now, a group of machines alone is not powerful, you need a framework to coordinate work across them.
Spark does just that, managing and coordinating the execution of tasks on data across a cluster of computers.

#### Spark Application

Spark Applications consist of a driver process and a set of executor processes.

